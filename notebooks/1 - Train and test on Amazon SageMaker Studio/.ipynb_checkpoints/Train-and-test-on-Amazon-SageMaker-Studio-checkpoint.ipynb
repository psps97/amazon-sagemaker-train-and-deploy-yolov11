{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b9f1aec",
   "metadata": {},
   "source": [
    "# Train and Test custom YOLOv11 on Amazon SageMaker Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369a9b33-2052-4c57-aa4f-b4b26e1c1d62",
   "metadata": {},
   "source": [
    "In this notebook we will train and test a custom YOLOv11 object detection CV model within Amazon SageMaker Studio. \n",
    "\n",
    "**Steps:**\n",
    "\n",
    "0. Initial configuration.\n",
    "1. Download a labeled dataset.\n",
    "3. Train the custom YOLOv11 model.\n",
    "4. Make predictions against the created model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e59f9ec-43f8-4040-bebc-4423afdc4b04",
   "metadata": {},
   "source": [
    "| ‚ö†Ô∏è WARNING: For this notebook to work, make sure to select the following settings in your jupyter environment: |\n",
    "| -- |\n",
    "Image: \"PyTorch 1.10 Python 3.8 GPU Optimized\"\n",
    "Instance_type: \"ml.g4dn.xlarge\" (fast launch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356f3d22-a857-40b5-8cb5-3185dd353233",
   "metadata": {},
   "source": [
    "## 0. Initial Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea75758-365c-41a4-b229-01bb7689848b",
   "metadata": {},
   "source": [
    "#### Download the YOLOv11 repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b786198-5500-4fbe-bc2b-b36bbf109125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git clone --quiet https://github.com/ultralytics/ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc188eb8-c621-404e-a0cf-bc9db2a4c00d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /opt/conda/lib/python3.11/site-packages (8.3.57)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (3.9.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (1.14.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (2.3.1.post300)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (0.18.1a0+405940f)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from ultralytics) (5.9.8)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.11/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (2.0.13)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-input ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4be8cb-417f-4269-b0c8-abc62063e737",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install --yes -c conda-forge opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a22293fe-b5c2-42c0-906a-add1fbf406e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import glob\n",
    "s3_resource = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddd1da6-e457-4e2b-acf3-d085643aa8c3",
   "metadata": {},
   "source": [
    "## 1. Download a labeled dataset with YOLOv11 expected format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfefb767-e740-42e7-8b5b-5c30abeff17b",
   "metadata": {},
   "source": [
    "Before we train a custom YOLOv11 model, we need to have a labeled dataset. \n",
    "In the previous notebook \"0 - Label your dataset with Amazon SageMaker GroundTruth\" you will be able to label your own dataset and transform it into YOLOv11 expected format or use an example custom dataset. Once you have run through one of the two options you will have available the S3 dataset location and labels used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3856bee1-e3ed-4304-b7de-3ee4417430a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_s3_uri = \"s3://sagemaker-us-west-2-986221661979/yolov5-process-2025-01-03-11-38-21-706/output/train/training_data\"\n",
    "#labels = ['car number']\n",
    "\n",
    "dataset_s3_uri = \"s3://sagemaker-us-west-2-986221661979/yolov11-process-2025-01-08-04-47-28-958/output/train/training_data\"\n",
    "labels = ['Airplane', 'Car', 'Ferry', 'Helicopter', 'Motorbike']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee81a053-6502-453a-805a-5e640df0733f",
   "metadata": {},
   "source": [
    "#### Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f2122a6-1c42-4ce7-b8d4-6e72a81475f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_s3_path(s3_path):\n",
    "    path_parts=s3_path.replace(\"s3://\",\"\").split(\"/\")\n",
    "    bucket=path_parts.pop(0)\n",
    "    key=\"/\".join(path_parts)\n",
    "    return bucket, key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6794fb3-de08-4527-8a73-683175121493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sagemaker-us-west-2-986221661979',\n",
       " 'yolov11-process-2025-01-08-04-47-28-958/output/train/training_data')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket,dataset_name = split_s3_path(dataset_s3_uri)\n",
    "bucket,dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e10c3229-ac6d-4cfc-9588-38b4431b92c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset(bucket_name, folder):\n",
    "    bucket = s3_resource.Bucket(bucket_name) \n",
    "    for obj in bucket.objects.filter(Prefix = folder):\n",
    "        if not os.path.exists(os.path.dirname(obj.key)):\n",
    "            os.makedirs(os.path.dirname(obj.key))\n",
    "        bucket.download_file(obj.key, obj.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32a60468-0295-42ed-93d0-2efef95a016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dataset(bucket, dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edd94f5-f78a-44a7-8c7d-a23cd3cfe90e",
   "metadata": {},
   "source": [
    "#### Lets explore our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44534876-38eb-4c01-a0ed-1447911ae23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolov11-process-2025-01-08-04-47-28-958/output/train/training_data/\n",
      "yolov11-process-2025-01-08-04-47-28-958/output/train/training_data/images\n",
      "yolov11-process-2025-01-08-04-47-28-958/output/train/training_data/images/train\n",
      "yolov11-process-2025-01-08-04-47-28-958/output/train/training_data/images/train/image_0007.jpeg\n",
      "yolov11-process-2025-01-08-04-47-28-958/output/train/training_data/images/train/image_0016.jpeg\n",
      "yolov11-process-2025-01-08-04-47-28-958/output/train/training_data/images/train/image_0019.jpeg\n",
      "yolov11-process-2025-01-08-04-47-28-958/output/train/training_data/images/train/image_0059.jpeg\n",
      "yolov11-process-2025-01-08-04-47-28-958/output/train/training_data/images/train/image_0061.jpeg\n",
      "yolov11-process-2025-01-08-04-47-28-958/output/train/training_data/images/train/image_0068.jpeg\n",
      "yolov11-process-2025-01-08-04-47-28-958/output/train/training_data/images/train/image_0123.jpeg\n",
      "yolov11-process-2025-01-08-04-47-28-958/output/train/training_data/images/train/image_0151.jpeg\n",
      "yolov11-process-2025-01-08-04-47-28-958/output/train/training_data/images/validation\n",
      "yolov11-process-2025-01-08-04-47-28-958/output/train/training_data/images/validation/image_0260.jpeg\n",
      "yolov11-process-2025-01-08-04-47-28-958/output/train/training_data/images/validation/image_0271.jpeg\n",
      "yolov11-process-2025-01-08-04-47-28-958/output/train/training_data/labels\n",
      "yolov11-process-2025-01-08-04-47-28-958/output/train/training_data/labels/train\n",
      "yolov11-process-2025-01-08-04-47-28-958/output/train/training_data/labels/train/image_0007.txt\n",
      "yolov11-process-2025-01-08-04-47-28-958/output/train/training_data/labels/train/image_0016.txt\n",
      "yolov11-process-2025-01-08-04-47-28-958/output/train/training_data/labels/train/image_0019.txt\n",
      "yolov11-process-2025-01-08-04-47-28-958/output/train/training_data/labels/train/image_0059.txt\n",
      "yolov11-process-2025-01-08-04-47-28-958/output/train/training_data/labels/train/image_0061.txt\n",
      "yolov11-process-2025-01-08-04-47-28-958/output/train/training_data/labels/train/image_0068.txt\n",
      "yolov11-process-2025-01-08-04-47-28-958/output/train/training_data/labels/train/image_0123.txt\n",
      "yolov11-process-2025-01-08-04-47-28-958/output/train/training_data/labels/train/image_0151.txt\n",
      "yolov11-process-2025-01-08-04-47-28-958/output/train/training_data/labels/validation\n",
      "yolov11-process-2025-01-08-04-47-28-958/output/train/training_data/labels/validation/image_0260.txt\n",
      "yolov11-process-2025-01-08-04-47-28-958/output/train/training_data/labels/validation/image_0271.txt\n"
     ]
    }
   ],
   "source": [
    "for filename in glob.iglob(dataset_name + '**/**', recursive=True):\n",
    "     print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d388275f-d930-44ac-be59-cd9e1312c7a4",
   "metadata": {},
   "source": [
    "# Now let's add these data sources to the data library in the yolov11 folder for our model to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "173b6a65-ab84-4444-ba85-079470c7bc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÌòÑÏû¨ ÏûëÏóÖ ÎîîÎ†âÌÜ†Î¶¨Ïùò Ï†àÎåÄ Í≤ΩÎ°ú: /home/sagemaker-user/amazon-sagemaker-train-and-deploy-yolov11/notebooks/1 - Train and test on Amazon SageMaker Studio\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_path = os.getcwd()\n",
    "print(\"ÌòÑÏû¨ ÏûëÏóÖ ÎîîÎ†âÌÜ†Î¶¨Ïùò Ï†àÎåÄ Í≤ΩÎ°ú:\", current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc3e2bb1-6ab6-4cda-bdaf-d86e4dc791e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: /home/sagemaker-user/amazon-sagemaker-train-and-deploy-yolov11/notebooks/1 - Train and test on Amazon SageMaker Studioyolov11-process-2025-01-08-04-47-28-958/output/train/training_data\n",
      "\n",
      "train: images/train\n",
      "\n",
      "val: images/validation\n",
      "\n",
      "names:\n",
      "\n",
      "  0: Airplane\n",
      "\n",
      "  1: Car\n",
      "\n",
      "  2: Ferry\n",
      "\n",
      "  3: Helicopter\n",
      "\n",
      "  4: Motorbike\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open(\"coco8.yaml\", 'w') as target:\n",
    "    target.write(\"path: {}\\n\".format(current_path+\"/\"+dataset_name))\n",
    "    target.write(\"train: images/train\\n\")\n",
    "    target.write(\"val: images/validation\\n\")\n",
    "    target.write(\"names:\\n\")\n",
    "    for i, label in enumerate(labels):\n",
    "        target.write(\"  {}: {}\\n\".format(i, label))\n",
    "        \n",
    "with open('coco8.yaml') as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27b95fd4-b8c7-49c8-958d-a4cf782bdced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: ../yolov11-process-2025-01-08-04-47-28-958/output/train/training_data\n",
      "train: images/train\n",
      "val: images/validation\n",
      "nc: 5\n",
      "names: ['Airplane', 'Car', 'Ferry', 'Helicopter', 'Motorbike']\n"
     ]
    }
   ],
   "source": [
    "with open(\"coco8.yaml\", 'w') as target:\n",
    "    target.write(\"path: ../{}\\n\".format(dataset_name))\n",
    "    target.write(\"train: images/train\\n\")\n",
    "    target.write(\"val: images/validation\\n\")\n",
    "    target.write(\"nc: {}\\n\".format(len(labels)))  # number of classes\n",
    "    target.write(\"names: [\")\n",
    "    \n",
    "    for i, label in enumerate(labels):\n",
    "        if i != len(labels) - 1:\n",
    "            target.write(\"'{}', \".format(label))\n",
    "        else:\n",
    "            target.write(\"'{}'\".format(label))\n",
    "    \n",
    "    target.write(\"]\\n\")\n",
    "\n",
    "# ÌååÏùº ÎÇ¥Ïö© ÌôïÏù∏\n",
    "with open('coco8.yaml') as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        print(line, end='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7b8fbd-ccdb-4440-af14-ea428bcc1cce",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Train the custom YOLOv11 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee2f8907-0640-4aa0-a4b0-80b061b43659",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.58 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.57 üöÄ Python-3.11.11 torch-2.3.1.post300 CPU (Intel Xeon Platinum 8259CL 2.50GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=coco8.yaml, epochs=30, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train6, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train6\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Dataset 'coco8.yaml' error ‚ùå \nDataset 'coco8.yaml' images not found ‚ö†Ô∏è, missing path '/home/sagemaker-user/amazon-sagemaker-train-and-deploy-yolov11/notebooks/1 - Train and test on Amazon SageMaker Studioyolov11-process-2025-01-08-04-47-28-958/output/train/training_data/images/validation'\nNote dataset download directory is '/home/sagemaker-user/amazon-sagemaker-train-and-deploy-yolov5/notebooks/1 - Train and test on Amazon SageMaker Studio/datasets'. You can update this in '/home/sagemaker-user/.config/Ultralytics/settings.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ultralytics/engine/trainer.py:562\u001b[0m, in \u001b[0;36mBaseTrainer.get_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myml\u001b[39m\u001b[38;5;124m\"\u001b[39m} \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetect\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpose\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    561\u001b[0m }:\n\u001b[0;32m--> 562\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_det_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ultralytics/data/utils.py:378\u001b[0m, in \u001b[0;36mcheck_det_dataset\u001b[0;34m(dataset, autodownload)\u001b[0m\n\u001b[1;32m    377\u001b[0m     m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNote dataset download directory is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATASETS_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. You can update this in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSETTINGS_FILE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 378\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(m)\n\u001b[1;32m    379\u001b[0m t \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: \nDataset 'coco8.yaml' images not found ‚ö†Ô∏è, missing path '/home/sagemaker-user/amazon-sagemaker-train-and-deploy-yolov11/notebooks/1 - Train and test on Amazon SageMaker Studioyolov11-process-2025-01-08-04-47-28-958/output/train/training_data/images/validation'\nNote dataset download directory is '/home/sagemaker-user/amazon-sagemaker-train-and-deploy-yolov5/notebooks/1 - Train and test on Amazon SageMaker Studio/datasets'. You can update this in '/home/sagemaker-user/.config/Ultralytics/settings.json'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolo11n.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m train_results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoco8.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# path to dataset YAML\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# number of training epochs\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# training image size\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# device to run on, i.e. device=0 or device=0,1,2,3 or device=cpu\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Evaluate model performance on the validation set\u001b[39;00m\n\u001b[1;32m     18\u001b[0m metrics \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mval()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ultralytics/engine/model.py:800\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    798\u001b[0m     args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path\n\u001b[0;32m--> 800\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_smart_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrainer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# manually set model only if not resuming\u001b[39;00m\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_model(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39myaml)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ultralytics/engine/trainer.py:133\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[0;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m check_model_file_from_stem(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mmodel)  \u001b[38;5;66;03m# add suffix, i.e. yolov8n -> yolov8n.pt\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch_distributed_zero_first(LOCAL_RANK):  \u001b[38;5;66;03m# avoid auto-downloading dataset multiple times\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtestset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Optimization utils init\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ultralytics/engine/trainer.py:566\u001b[0m, in \u001b[0;36mBaseTrainer.get_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# for validating 'yolo train data=url.zip' usage\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 566\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(emojis(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclean_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m error ‚ùå \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m], data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dataset 'coco8.yaml' error ‚ùå \nDataset 'coco8.yaml' images not found ‚ö†Ô∏è, missing path '/home/sagemaker-user/amazon-sagemaker-train-and-deploy-yolov11/notebooks/1 - Train and test on Amazon SageMaker Studioyolov11-process-2025-01-08-04-47-28-958/output/train/training_data/images/validation'\nNote dataset download directory is '/home/sagemaker-user/amazon-sagemaker-train-and-deploy-yolov5/notebooks/1 - Train and test on Amazon SageMaker Studio/datasets'. You can update this in '/home/sagemaker-user/.config/Ultralytics/settings.json'"
     ]
    }
   ],
   "source": [
    "#!python yolov5/train.py --workers 4 --device 0 --img 640 --batch 8 --epochs 10 --data yolov5/data/custom-model.yaml --weights yolov5s.pt --cache\n",
    "\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Train the model\n",
    "train_results = model.train(\n",
    "    data=\"coco8.yaml\",  # path to dataset YAML\n",
    "    epochs=30,  # number of training epochs\n",
    "    imgsz=640,  # training image size\n",
    "    device=\"cpu\",  # device to run on, i.e. device=0 or device=0,1,2,3 or device=cpu\n",
    ")\n",
    "\n",
    "# Evaluate model performance on the validation set\n",
    "metrics = model.val()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10041e53-9d07-4636-a81e-af1ac71c0db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform object detection on an image\n",
    "results = model(\"./validation_dataset/image_0094.jpg\")\n",
    "results[0].show()\n",
    "\n",
    "# Export the model to ONNX format\n",
    "path = model.export(format=\"onnx\")  # return path to exported model\n",
    "print(\"export model path:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d5835f-e975-408f-97f1-3c47f44ba56e",
   "metadata": {},
   "source": [
    "## 4. Make inferences with the created model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3dfee9-e2fc-4058-a5aa-2ffe186d4a1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!python yolov5/detect.py --weights yolov5/runs/train/exp/weights/best.pt --img 640 --conf 0.5 --source \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660fdab9-e4d8-4a76-8e0e-4ca98fbecd4c",
   "metadata": {},
   "source": [
    "| ‚ö†Ô∏è WARNING: Remember to shutdown the instance once finalized with this notebook to prevent unnecesary charges. Head to running Terminals and Kernels tab and shutdown the running instance. |\n",
    "| -- |"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
